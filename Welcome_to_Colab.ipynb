{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevSecOps-Stack/simple-rag/blob/main/Welcome_to_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd8a1607"
      },
      "source": [
        "%pip install pdfplumber pinecone openai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ef0066"
      },
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Use Colab's Secrets Manager for API keys\n",
        "PINECONE_API_KEY = userdata.get(\"PINECONE_API_KEY\")\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "import time\n",
        "from typing import List, Dict\n",
        "\n",
        "import pdfplumber\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "# OpenAI SDK (>=1.0)\n",
        "from openai import OpenAI\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "import pinecone\n",
        "\n",
        "print(f\"Pinecone client version: {pinecone.__version__}\")\n",
        "\n",
        "# --------- CONFIG ---------\n",
        "# Use Colab's Secrets Manager for API keys\n",
        "PINECONE_API_KEY = userdata.get(\"PINECONE_API_KEY\")\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "\n",
        "INDEX_NAME = \"document-index\"\n",
        "EMBED_MODEL = \"text-embedding-3-small\"   # 1536 dims\n",
        "EMBED_DIM = 1536\n",
        "GEN_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")  # adjust if you prefer\n",
        "\n",
        "# --------- CLIENTS ---------\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# --------- INDEX SETUP ---------\n",
        "def ensure_index(name: str, dimension: int) -> None:\n",
        "    \"\"\"Create the Pinecone serverless index if it doesn't exist.\"\"\"\n",
        "    # Robust existence check\n",
        "    try:\n",
        "        pc.describe_index(name)\n",
        "        return\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    pc.create_index(\n",
        "        name=name,\n",
        "        dimension=dimension,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")  # ✅ correct region\n",
        "    )\n",
        "    # Optionally wait a moment for readiness\n",
        "    # New serverless indexes are usually ready very quickly\n",
        "    for _ in range(30):\n",
        "        try:\n",
        "            desc = pc.describe_index(name)\n",
        "            # Some SDK versions expose \"status\" with \"ready\"\n",
        "            status = getattr(desc, \"status\", None) or getattr(desc, \"index\", {}).get(\"status\")\n",
        "            if (isinstance(status, dict) and status.get(\"ready\")) or not status:\n",
        "                break\n",
        "        except Exception:\n",
        "            pass\n",
        "        time.sleep(1)\n",
        "\n",
        "ensure_index(INDEX_NAME, EMBED_DIM)\n",
        "index = pc.Index(INDEX_NAME)\n",
        "\n",
        "# --------- UTILITIES ---------\n",
        "def pdf_to_text(pdf_path: str) -> str:\n",
        "    text = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text() or \"\"\n",
        "            if page_text.strip():\n",
        "                text.append(page_text)\n",
        "    return \"\\n\".join(text)\n",
        "\n",
        "def chunk_text(text: str, max_words: int = 300, overlap: int = 50) -> List[str]:\n",
        "    \"\"\"\n",
        "    Simple word-based chunker (approx token-safe).\n",
        "    ~300 words ≈ 400–600 tokens depending on content.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    n = len(words)\n",
        "    while start < n:\n",
        "        end = min(start + max_words, n)\n",
        "        chunk = \" \".join(words[start:end])\n",
        "        if chunk.strip():\n",
        "            chunks.append(chunk)\n",
        "        if end == n:\n",
        "            break\n",
        "        start = max(0, end - overlap)\n",
        "    return chunks\n",
        "\n",
        "def embed(texts: List[str]) -> List[List[float]]:\n",
        "    # Batching recommended for speed; here we keep it simple\n",
        "    resp = client.embeddings.create(model=EMBED_MODEL, input=texts)\n",
        "    return [d.embedding for d in resp.data]\n",
        "\n",
        "# --------- UPSERT ---------\n",
        "def upsert_pdf(pdf_path: str, doc_id: str = None, namespace: str = None) -> List[str]:\n",
        "    \"\"\"\n",
        "    - Extracts text from PDF\n",
        "    - Chunks it\n",
        "    - Embeds & upserts to Pinecone with metadata\n",
        "    Returns list of vector IDs written.\n",
        "    \"\"\"\n",
        "    full_text = pdf_to_text(pdf_path)\n",
        "    if not full_text.strip():\n",
        "        raise ValueError(f\"No extractable text from: {pdf_path}\")\n",
        "\n",
        "    chunks = chunk_text(full_text, max_words=320, overlap=60)\n",
        "    vecs = embed(chunks)\n",
        "\n",
        "    written_ids = []\n",
        "    to_upsert = []\n",
        "    base_id = doc_id or str(uuid.uuid4())\n",
        "\n",
        "    for i, (chunk, vec) in enumerate(zip(chunks, vecs)):\n",
        "        vid = f\"{base_id}::chunk::{i:04d}\"\n",
        "        to_upsert.append({\n",
        "            \"id\": vid,\n",
        "            \"values\": vec,\n",
        "            \"metadata\": {\n",
        "                \"text\": chunk,\n",
        "                \"source\": os.path.basename(pdf_path),\n",
        "                \"doc_id\": base_id,\n",
        "                \"chunk_index\": i\n",
        "            }\n",
        "        })\n",
        "        written_ids.append(vid)\n",
        "\n",
        "    # Upsert in one go (split if you have thousands)\n",
        "    index.upsert(vectors=to_upsert, namespace=namespace)\n",
        "    return written_ids\n",
        "\n",
        "# --------- QUERY ---------\n",
        "def query_pinecone(query_text: str, top_k: int = 5, namespace: str = None) -> List[Dict]:\n",
        "    q_vec = embed([query_text])[0]\n",
        "    res = index.query(\n",
        "        vector=q_vec,\n",
        "        top_k=top_k,\n",
        "        include_metadata=True,\n",
        "        namespace=namespace\n",
        "    )\n",
        "    # SDK returns .matches as list of objects or dicts depending on version\n",
        "    matches = getattr(res, \"matches\", None) or res.get(\"matches\", [])\n",
        "    return matches\n",
        "\n",
        "# --------- GENERATION ---------\n",
        "def generate_answer(query: str, context_chunks: List[str]) -> str:\n",
        "    system = (\n",
        "        \"You answer strictly based on the provided context. \"\n",
        "        \"If the answer isn't in context, say you don't know.\"\n",
        "    )\n",
        "    context = \"\\n\\n\".join(f\"- {c}\" for c in context_chunks)\n",
        "    user = f\"Context:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer in 6-8 concise sentences.\"\n",
        "\n",
        "    chat = client.chat.completions.create(\n",
        "        model=GEN_MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": user},\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    return chat.choices[0].message.content.strip()\n",
        "\n",
        "def answer_with_rag(query: str, top_k: int = 5, namespace: str = None) -> str:\n",
        "    matches = query_pinecone(query, top_k=top_k, namespace=namespace)\n",
        "    # Safely collect texts\n",
        "    ctx = []\n",
        "    for m in matches:\n",
        "        md = getattr(m, \"metadata\", None) or m.get(\"metadata\", {}) or {}\n",
        "        t = md.get(\"text\")\n",
        "        if t:\n",
        "            ctx.append(t)\n",
        "    return generate_answer(query, ctx)\n",
        "\n",
        "# --------- EXAMPLES ---------\n",
        "if __name__ == \"__main__\":\n",
        "    # 1) Ingest a PDF\n",
        "    upsert_pdf(\"/content/OpenShift_Container_Platform-4.18-Architecture-en-US.pdf\")\n",
        "\n",
        "    # 2) Query & answer\n",
        "    print(\"Querying…\")\n",
        "    q = \"can you print entire page number 1\"\n",
        "    print(answer_with_rag(q))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otZ0bHQnrpH1",
        "outputId": "410bfd47-074e-4aea-a71d-0977b20888bd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinecone client version: 7.3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat328' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat360' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat381' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat386' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat409' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat414' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat437' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat442' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat518' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat523' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat535' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat548' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat553' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat565' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat592' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat633' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat711' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat764' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat785' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'Pat958' is an invalid float value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Querying…\n",
            "I don't know.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome to Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}